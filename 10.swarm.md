# Swarm 安装与使用练习

Swarm是Docker公司在2014年12月初发布的一套较为简单的工具，用来管理Docker集群，它将一群Docker宿主机变成一个单一的
，虚拟的主机。Swarm使用标准的Docker API接口作为其前端访问入口，换言之，
各种形式的Docker Client(docker client in go, docker_py, docker等)均可以直接与Swarm通信。Swarm几乎全部用Go语言来完成开发，
Swarm0.2发布，相比0.1版本，0.2版本增加了一个新的策略来调度集群中的容器，使得在可用的节点上传播它们，以及支持更多的Docker命令以及集群驱动

![architecture](./pic/arch.png)

![architecture](./pic/arch1.png)


## 安装

```
docker pull dockerswarm/swarm

1.在使用Swarm进行集群管理之前，需要先把准备加入集群的所有的节点的docker deamon的监听端口修改为0.0.0.0:2375，可以直接使用
  docker –H tcp://0.0.0.0:2375 &

2. 在Docker配置文件中增加
  DOCKER_OPTS="-H 0.0.0.0:2375 –H unix:///var/run/docker.sock"
  
  注意：一定是要在所有的节点上进行修改,修改之后要重启docker deamon
  
  service docker restart
  
3. 第一种方法：使用Docker Hub上面内置的服务发现功能

  a. 在任何一个节点上面执行swarm create命令来创建一个集群标志。这条命令执行完毕之后，swarm会前往Docker Hub上内建的发现服务中获取一个全球唯一的token，
  用以唯一的标识swarm管理的Docker集群

    docker run --rm swarm create

    返回的token是d947b55aa8fb9198b5d13ad81f61ac4d（类似这种），这个token一定要记住，因为接下来的操作都会用到这一个token

    b. 第二步：在所有的要加入集群的机器上面执行swarm join命令，把机器加入集群
      docker run –-rm swarm join –addr=ip_address:2375 token://d947b55aa8fb9198b5d13ad81f61ac4d

    c. 第三步 
      启动swarm manager。
      管理节点，运行
        docker run –d –p 2376:2375 swarm manage token:// d947b55aa8fb9198b5d13ad81f61ac4d

      重点内容需要注意的是：在这条命令中
      ，第一：要以daemon的形式运行swarm；第二：端口映射：2376可以更换成任何一个本机没有占用的端口，一定不能是2375，否则就会出问题。

      然后通过 docker run --rm swarm list token:// d947b55aa8fb9198b5d13ad81f61ac4d 可以查看加入集群的机器


      info命令可以换成任何一个Swarm支持的docker命令
      docker –H 10.13.181.83:2376 info
第二种方法：使用文件

a.在master这台机器上新建一个文件，把要加入集群的机器的IP地址写进去
b.执行swarm manage命令
   docker run –d –p 2376:2375 –v $(pwd)/cluster:/tmp/cluster swarm manage file:///tmp/cluster
注意：这里一定要使用-v命令，因为cluster文件是在本机上面，启动的容器默认是访问不到的，所以要通过-v命令共享。还有，file:///千万不能忘记了。

docker run –rm –v $(pwd)/cluster:/tmp/cluster swarm list file:///tmp/cluster   

```

##Swarm调度策略
warm在schedule节点运行容器的时候，会根据指定的策略来计算最适合运行容器的节点，目前支持的策略有：spread, binpack, random.

Random顾名思义，就是随机选择一个Node来运行容器，一般用作调试用，spread和binpack策略会根据各个节点的可用的CPU, RAM以及正在运行的容器的数量来计算应该运行容器的节点。

在同等条件下，Spread策略会选择运行容器最少的那台节点来运行新的容器，binpack策略会选择运行容器最集中的那台机器来运行新的节点(The binpack strategy causes Swarm to optimize for the Container which is most packed.)。

使用Spread策略会使得容器会均衡的分布在集群中的各个节点上运行，一旦一个节点挂掉了只会损失少部分的容器。

Binpack策略最大化的避免容器碎片化，就是说binpack策略尽可能的把还未使用的节点留给需要更大空间的容器运行，尽可能的把容器运行在一个节点上面。


##过滤器

Constraint Filter

通过label来在指定的节点上面运行容器。这些label是在启动docker daemon时指定的，也可以写在/etc/default/docker这个配置文件里面。

$ sudo docker run –H 10.13.181.83:2376 –name redis_083 –d –e constraint:label==083 redis
Affinity Filter

使用-e affinity:container==container_name / container_id –-name container_1可以让容器container_1紧挨着容器container_name / container_id执行，也就是说两个容器在一个node上面执行(You can schedule 2 containers and make the container #2 next to the container #1.)

先在一台机器上启动一个容器

$ sudo docker -H 10.13.181.83:2376 run --name redis_085 -d -e constraint:label==085 redis
接下来启动容器redis_085_1，让redis_085_1紧挨着redis_085容器运行，也就是在一个节点上运行

$ sudo docker –H 10.13.181.83:2376 run –d –name redis_085_1 –e affinity:container==redis_085 redis
通过-e affinity:image=image_name命令可以指定只有已经下载了image_name的机器才运行容器(You can schedule a container only on nodes where the images are already pulled)

下面命令在只有redis镜像的节点上面启动redis容器:

$ sudo docker –H 100.13.181.83:2376 run –name redis1 –d –e affinity:image==redis redis
下面这条命令达到的效果是：在有redis镜像的节点上面启动一个名字叫做redis的容器，如果每个节点上面都没有redis容器，就按照默认的策略启动redis容器。

$ sudo docker -H 10.13.181.83:2376 run -d --name redis -e affinity:image==~redis redis
Port filter

Port也会被认为是一个唯一的资源

$ sudo docker -H 10.13.181.83:2376 run -d -p 80:80 nginx
执行完这条命令，任何使用80端口的容器都是启动失败。
